# Intent Hub 配置模板

# --- Flask 配置 ---
FLASK_HOST=0.0.0.0
FLASK_PORT=5000
FLASK_DEBUG=False

# --- Qdrant 向量数据库配置 ---
# 如果使用 Docker Compose 部署，QDRANT_URL 建议设置为 http://qdrant:6333
QDRANT_URL=http://qdrant:6333
QDRANT_COLLECTION=intent_hub_routes
QDRANT_API_KEY=

# --- Embedding 模型配置 ---
# 默认使用 Qwen-Embedding 模型，支持 HuggingFace Inference API 或本地加载
EMBEDDING_MODEL_NAME=Qwen/Qwen3-Embedding-0.6B
EMBEDDING_DEVICE=cpu
# 如果提供 Token，则优先使用 HuggingFace Inference API
HUGGINGFACE_ACCESS_TOKEN=
HUGGINGFACE_PROVIDER=
HUGGINGFACE_TIMEOUT=60

# --- LLM 大模型配置 (用于生成提问和修复建议) ---
# 支持 provider: deepseek, openrouter, doubao, qwen, gemini
LLM_PROVIDER=deepseek
LLM_API_KEY=your_api_key_here
LLM_BASE_URL=https://api.deepseek.com
LLM_MODEL=deepseek-chat
LLM_TEMPERATURE=0.7

# --- 数据持久化配置 ---
# 建议将数据目录挂载到外部卷
INTENT_HUB_DATA_DIR=/app/data
ROUTES_CONFIG_PATH=/app/data/routes_config.json
SETTINGS_FILE_PATH=/app/data/settings.json

# --- 认证配置 ---
AUTH_ENABLED=True
DEFAULT_USERNAME=admin
DEFAULT_PASSWORD=123456
# 多个 API Key 请用逗号分隔
API_KEYS=
# 预测接口专用的 Telestar 认证 Key
PREDICT_AUTH_KEY=
